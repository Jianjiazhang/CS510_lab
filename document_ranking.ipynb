{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "publication_data = pd.read_csv('publication.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "publications_id_document_dict = dict()\n",
    "for i in range(0, len(publication_data)):\n",
    "    pub_info = publication_data.iloc[i]\n",
    "    s_id = pub_info[0]\n",
    "    document = str(pub_info[1]) + \" \" + str(pub_info[2]) + \" \" + str(pub_info[3])\n",
    "    publications_id_document_dict[s_id] = document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "publication_candidates = dict()\n",
    "with jsonlines.open('candidate_document_headQ_recommendation_top100.jsonl') as reader:\n",
    "    for item in reader:\n",
    "        s_id = item[\"s_id\"]\n",
    "        candidate_docs_dict = item[\"candidate_docs\"]\n",
    "        publication_candidates[s_id] = list(candidate_docs_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidate_data = pd.read_csv('dataset.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidate_id_document_dict = dict()\n",
    "for i in range(0, len(candidate_data)):\n",
    "    candidate_info = candidate_data.iloc[i]\n",
    "    c_id = candidate_info[0]\n",
    "    document = str(candidate_info[1]) + \" \" + str(candidate_info[2]) + \" \" + str(candidate_info[3])\n",
    "    candidate_id_document_dict[c_id] = document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    intersect = set([value for value in lst1 if value in lst2])\n",
    "    return intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def query_likelihood_retrieval(q, d, C_model, alpha_d, lambda_, mu):\n",
    "    word_list = list(intersection(q,d))\n",
    "    scores = [0,0,0]\n",
    "    # calculate c(w|d)\n",
    "    count_of_w_in_d = dict()\n",
    "    for word in d:\n",
    "        if word in word_list:\n",
    "            if word not in count_of_w_in_d:\n",
    "                count_of_w_in_d[word]=0\n",
    "            count_of_w_in_d[word]+=1\n",
    "        #calculate sum of log(P(w|c)) for every w in d\n",
    "        scores[0] += math.log(C_model[word])\n",
    "        \n",
    "    # calculate non-smoothing_query_likelihood\n",
    "    for word in word_list:\n",
    "        scores[0] += math.log((count_of_w_in_d[word]/len(word_list))/(alpha_d*C_model[word]))\n",
    "    scores[0] += len(d) * math.log(alpha_d)\n",
    "    \n",
    "    # calculate c(w|q)\n",
    "    count_of_w_in_q = dict()\n",
    "    for word in q:\n",
    "        if word in word_list:\n",
    "            if word not in count_of_w_in_q:\n",
    "                count_of_w_in_q[word]=0\n",
    "            count_of_w_in_q[word]+=1\n",
    "    # JM smoothing\n",
    "    for word in word_list:\n",
    "        scores[1] += count_of_w_in_q[word] + math.log(1 + (1-lambda_)/lambda_*count_of_w_in_d[word]/(len(d)*C_model[word]))\n",
    "        \n",
    "    # Dir smoothing\n",
    "    for word in word_list:\n",
    "        scores[2] += count_of_w_in_q[word] + math.log(1 + count_of_w_in_d[word]/(mu*C_model[word]))\n",
    "    scores[2] += len(q) * math.log(mu/(mu+len(d)))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_document_ranking = dict()\n",
    "for publication in publication_candidates.keys():\n",
    "    candidates = publication_candidates[publication]\n",
    "    # build the background model: A dict that contains P(w|C)\n",
    "    collection = publications_id_document_dict[publication].split()\n",
    "    for candidate in candidates:\n",
    "        if candidate in candidate_id_document_dict:\n",
    "            collection += candidate_id_document_dict[candidate].split()\n",
    "    back_ground_model = dict()\n",
    "    for word in collection:\n",
    "        if word not in back_ground_model:\n",
    "            back_ground_model[word] = 0\n",
    "        back_ground_model[word] +=1\n",
    "    length = len(collection)\n",
    "    for word in back_ground_model.keys():\n",
    "        back_ground_model[word] /= length\n",
    "    # Calculate the query likelihood probability\n",
    "    document_id_score_dict = dict()\n",
    "    document_id_jmscore_dict = dict()\n",
    "    document_id_dirscore_dict = dict()\n",
    "    for candidate in candidates:\n",
    "        if candidate in candidate_id_document_dict:\n",
    "            q = publications_id_document_dict[publication].split()\n",
    "            d = candidate_id_document_dict[candidate].split()\n",
    "            alpha_d = 0.1\n",
    "            lambda_ = 0.5\n",
    "            mu = 0.5\n",
    "            scores = query_likelihood_retrieval(q,d,back_ground_model,alpha_d, lambda_, mu)\n",
    "            document_id_score_dict[candidate] = scores[0]\n",
    "            document_id_jmscore_dict[candidate] = scores[1]\n",
    "            document_id_dirscore_dict[candidate] = scores[2]\n",
    "    # Get the top 10 rank\n",
    "    rank_non_smoothing = sorted(document_id_score_dict, key=document_id_score_dict.get)[-3:]\n",
    "    rank_jm_smoothing = sorted(document_id_jmscore_dict, key=document_id_jmscore_dict.get)[-3:]\n",
    "    rank_dir_smoothing = sorted(document_id_dirscore_dict, key=document_id_dirscore_dict.get)[-3:]\n",
    "    rank_non_smoothing.reverse()\n",
    "    rank_jm_smoothing.reverse()\n",
    "    rank_dir_smoothing.reverse()\n",
    "    #write to the ranking dictionary\n",
    "    candidate_document_ranking[publication] = dict()\n",
    "    candidate_document_ranking[publication]['normal'] = rank_non_smoothing\n",
    "    candidate_document_ranking[publication]['normal_score'] = [document_id_score_dict[d] for d in rank_non_smoothing]\n",
    "    candidate_document_ranking[publication]['jm'] = rank_jm_smoothing\n",
    "    candidate_document_ranking[publication]['jm_score'] = [document_id_jmscore_dict[d] for d in rank_jm_smoothing]\n",
    "    candidate_document_ranking[publication]['dir'] = rank_dir_smoothing\n",
    "    candidate_document_ranking[publication]['dir_score'] = [document_id_dirscore_dict[d] for d in rank_dir_smoothing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'normal': ['datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de621835', 'datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de619110', 'ZA7574'], 'normal_score': [-43.70560709101471, -48.27494507223969, -63.916460561092165], 'jm': ['ZA6702', 'ZA7573', 'ZA6597'], 'jm_score': [86.62126814656934, 83.37498113198336, 79.18381749171365], 'dir': ['datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de621835', 'datasearch-httpwww-da-ra-deoaip--oaioai-da-ra-de619110', 'ZA7574'], 'dir_score': [-318.20031215613153, -351.1137517044994, -394.2475009517014]}\n"
     ]
    }
   ],
   "source": [
    "print(candidate_document_ranking['gesis-ssoar-62031'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python371jvsc74a57bd040996f4069178cd5639bcf5d575b44f5c0fb70533d0ddb3cdb11b5efa4ba55b5",
   "display_name": "Python 3.7.1 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
